{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нахождение меток для data/posts.xls\n",
    "\n",
    "Для определения меток исходного датасета мы будем использовать\n",
    " \n",
    "предобученную модель  [DeepPavlov/rubert-base-cased](https://huggingface.co/cointegrated/rubert-base-cased-nli-threeway?)\n",
    "\n",
    "Но сперва обработаем posts.xls\n",
    "\n",
    "## Предобработка posts.xls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_excel('../data/posts.xlsx')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>telegram_id</th>\n",
       "      <th>text</th>\n",
       "      <th>datetime</th>\n",
       "      <th>category_id</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>title</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>157314</td>\n",
       "      <td>❗️Восстановление аммиакопровода Тольятти — Оде...</td>\n",
       "      <td>2023-06-07 11:40:06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1001394050290</td>\n",
       "      <td>Восстановление аммиакопровода займет до 3 меся...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18940</td>\n",
       "      <td>Дополнительные 39 миллионов рублей были выделе...</td>\n",
       "      <td>2023-06-07 11:34:56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1001098860759</td>\n",
       "      <td>Выделены дополнительные 39 млн рублей на соцуч...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4868</td>\n",
       "      <td>«Россия уничтожена санкциями»\\n               ...</td>\n",
       "      <td>2023-06-07 11:03:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1001797434593</td>\n",
       "      <td>«Россия уничтожена санкциями»\\n               ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>157315</td>\n",
       "      <td>❗️Правоохранители провели обыски в министерств...</td>\n",
       "      <td>2023-06-07 11:50:06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1001394050290</td>\n",
       "      <td>Обыски в минобразования Дагестана по делу о вы...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>157317</td>\n",
       "      <td>Реконструкция пропускного пункта \"Верхний Ларс...</td>\n",
       "      <td>2023-06-07 12:10:25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1001394050290</td>\n",
       "      <td>Реконструкция пропускного пункта \"Верхний Ларс...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id telegram_id                                               text  \\\n",
       "0   1      157314  ❗️Восстановление аммиакопровода Тольятти — Оде...   \n",
       "1   2       18940  Дополнительные 39 миллионов рублей были выделе...   \n",
       "2   3        4868  «Россия уничтожена санкциями»\\n               ...   \n",
       "3   4      157315  ❗️Правоохранители провели обыски в министерств...   \n",
       "4  16      157317  Реконструкция пропускного пункта \"Верхний Ларс...   \n",
       "\n",
       "              datetime category_id      channel_id  \\\n",
       "0  2023-06-07 11:40:06         NaN  -1001394050290   \n",
       "1  2023-06-07 11:34:56         NaN  -1001098860759   \n",
       "2  2023-06-07 11:03:05         NaN  -1001797434593   \n",
       "3  2023-06-07 11:50:06         NaN  -1001394050290   \n",
       "4  2023-06-07 12:10:25         NaN  -1001394050290   \n",
       "\n",
       "                                               title Unnamed: 7 Unnamed: 8  \\\n",
       "0  Восстановление аммиакопровода займет до 3 меся...        NaN        NaN   \n",
       "1  Выделены дополнительные 39 млн рублей на соцуч...        NaN        NaN   \n",
       "2  «Россия уничтожена санкциями»\\n               ...        NaN        NaN   \n",
       "3  Обыски в минобразования Дагестана по делу о вы...        NaN        NaN   \n",
       "4  Реконструкция пропускного пункта \"Верхний Ларс...        NaN        NaN   \n",
       "\n",
       "  Unnamed: 9  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                169871\n",
       "unique                                               157940\n",
       "top       This channel is unavailable due to copyright i...\n",
       "freq                                                    166\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151531, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Удалим дубликаты\n",
    "data = data.drop_duplicates(subset=['text'], keep=False, ignore_index=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                151531\n",
       "unique                                               151531\n",
       "top       ❗️Восстановление аммиакопровода Тольятти — Оде...\n",
       "freq                                                      1\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 151531 entries, 0 to 151530\n",
      "Series name: text\n",
      "Non-Null Count   Dtype \n",
      "--------------   ----- \n",
      "151531 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data['text'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel('../data/handled_posts.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pd.isnull(data['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вычисление меток"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers sentencepiece --quiet\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_checkpoint = 'cointegrated/rubert-base-cased-nli-threeway'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_zero_shot(text, label_texts, model, tokenizer, label='entailment', normalize=True):\n",
    "    label_texts\n",
    "    tokens = tokenizer([text] * len(label_texts), label_texts, truncation=True, return_tensors='pt', padding=True)\n",
    "    with torch.inference_mode():\n",
    "        result = torch.softmax(model(**tokens.to(model.device)).logits, -1)\n",
    "    proba = result[:, model.config.label2id[label]].cpu().numpy()\n",
    "    if normalize:\n",
    "        proba /= sum(proba)\n",
    "    return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Финансы', 'Технологии', 'Политика', \n",
    "           'Шоубиз', 'Fashion', 'Крипта', 'Путешествия/релокация', \n",
    "           'Образовательный контент', 'Развлечения', 'Общее']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "from tqdm import tqdm\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "unhandled_posts = []\n",
    "\n",
    "with open('../data/labels.csv', 'w', encoding='cp1251') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    for indx, paper in enumerate(tqdm(data['text'])):\n",
    "        try:\n",
    "            proba = predict_zero_shot(paper, classes, model, tokenizer)\n",
    "            writer.writerow(classes[argmax(proba)])\n",
    "        except:\n",
    "            unhandled_posts.append(indx)\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
